{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Boardgame Recommender neural network <br>\n",
    "Author: Austin Chou<br>\n",
    "Date: 2018-11-07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "\n",
    "The intent of this exercise is to:<br>\n",
    "\n",
    "1) Practice programming and data manipulation in python <br>\n",
    "2) Implement NLP approach to develop a boardgame recommender system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem\n",
    "\n",
    "There are a variety of methods for building recommendation engines. I want to apply approaches for boardgames which is a personal hobby.\n",
    "\n",
    "The website \"https://boardgamegeek.com/\" has over 10000 ranked boardgames (includes expansions and variations of the same base boardgame). For new boardgame collectors and hobbyists, the number of choices is quite astronomical. Even if we reduce look at just the games released in the 2017, there are over 3000 boardgames.\n",
    "\n",
    "Thus the primary problem is to identify patterns to help recommend boardgames to people who are looking to grow their boardgame collection.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach\n",
    "\n",
    "The approach I chose was inspired by a basic Natural Language Processing technique: Continuous Bag of Words (CBOW). In CBOW (and its brother the Skip-gram), words are essentially defined by its surrounding words. In the case of CBOW, we can be given a set of words (as in a sentence) and predict what word is most likely surrounded by that set of words.  \n",
    "\n",
    "In that way, I thought it would be interesting to build a boardgame recommender based off which boardgame is most likely to appear with any set of boardgames. This would be quite different from defining boardgames by their defined features (Categories, Mechanics, player count, etc).\n",
    "\n",
    "Of course, there are limitations to this approach (assuming the model can be built): Because it is reliant on existing collections, new boardgames released each year would automatically be ignored by the model (since no one would own them and they appear on very few collections at a time). The CBOW approach would probably work best for a new hobbyist who is interested in building a collection of games that have been around for a while (and can be found in many collections)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load appropriate functions, packages, and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in functions\n",
    "%run functions-bgg_get.py\n",
    "\n",
    "# General libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "# Regular expression\n",
    "import re\n",
    "\n",
    "# Flags to rerun code chunks\n",
    "recollect = False\n",
    "reclean = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Training Matrix: Aggregate all collections\n",
    "\n",
    "The first step is to take all the player collections we have scraped and turn them into one giant matrix. CBOW and other NLP techniques utilize One Hot Encoding; analogously, we will one hot encode our boardgames. That means each row represents a Collection, and each entry in that Collection represents a game. <br>\n",
    " - If the value is a 0, then the game does not exist in the Collection. <br>\n",
    " - If the value is a 1, then the game exists in the Collection.\n",
    "\n",
    "We will do additional cleaning and apply some limitations to try and reduce the number of features we will be feeding into our model: <br>\n",
    " - Limit the number of games we care about. I chose to only recommend from the top 5000 games (as opposed to trying to consider all 10000+).<br>\n",
    " - Remove games from users' collections that fall below a certain Rating by the user. If the user didn't rate the game, we'll use the overall Rating found on boardgamegeek. The idea is that if the game doesn't rate highly, it should not be valued for recommendation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of games we are considering (from top rated)\n",
    "total = 5000\n",
    "\n",
    "# Get the game_list\n",
    "games_list = pd.read_csv('bgg_id_output.csv')\n",
    "#Remove all NaN rows\n",
    "games_list.dropna(axis=0,how='any',inplace=True)\n",
    "games_list.reset_index(drop=True,inplace=True)\n",
    "#There are repeat titles in the list. Remove them.\n",
    "rep_games_idx = games_list[games_list['Game'].duplicated()].index.tolist() #Returns the indices of all repeat titles. This list does NOT include the first appearance\n",
    "games_list.drop(games_list.index[rep_games_idx],inplace=True)\n",
    "games_list.reset_index(drop=True,inplace=True)\n",
    "#Reduce to # of games to consider\n",
    "games_list = games_list.loc[:total,:]\n",
    "\n",
    "# Get the playerlist\n",
    "playerlist = pd.read_excel('playerlist.xlsx')\n",
    "# Generate the bgg dictionary of indices to game\n",
    "games, games_decode = bgg_dict(games_list, total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Dropbox\\DS\\bgg github\\Boardgame-Recommender-Project\\functions-bgg_get.py:421: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  collection.drop(collection.index[low_bgg_idx],inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Have a list for removed users (those whose collections fall below 1 game after cleanup)\n",
    "removed_users = []\n",
    "\n",
    "for i in range(0,len(playerlist)):\n",
    "    # Get the user file\n",
    "    #print(str(ct) + ': ' + str(user))\n",
    "    user = playerlist['Username'][i]\n",
    "    file = str(user) + '_raw.csv'\n",
    "    user_collection = pd.read_csv(file, sep='\\t', encoding='ISO-8859-1')\n",
    "    #Drop the column 'Unnamed: 0' that is used to number the rows\n",
    "    user_collection.drop('Unnamed: 0', inplace=True, axis=1)\n",
    "    \n",
    "    # Apply RatingThreshold\n",
    "    user_collection_cleaned = RatingThreshold(user_collection)\n",
    "    \n",
    "    # Check if user has more than 1 game after cleaning the collection\n",
    "    if user_collection_cleaned.shape[0] == 1:\n",
    "        print('Less than 1 game added')\n",
    "        removed_users = removed_users + [user_collection_cleaned.loc[0,'User']]\n",
    "    else:\n",
    "        # Vectorize the collection\n",
    "        user_vector = games2vec(user_collection_cleaned['Game'], games)\n",
    "        #Add user number\n",
    "        user_vector = np.append([[i]], user_vector, axis=1)\n",
    "        #Create row as a dataframe\n",
    "        user_row = pd.DataFrame(user_vector, columns=list(['User']) + list(games_list['Game']))\n",
    "        \n",
    "        # Append to existing aggregate_collections dataframe\n",
    "        if i == 0:\n",
    "            aggregate_collections = user_row\n",
    "        else:\n",
    "            aggregate_collections = pd.concat([aggregate_collections, user_row])\n",
    "\n",
    "aggregate_collections.to_csv('Coded user collections.csv',encoding='utf-8')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of our matrix:\n",
      "(211, 5002)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensions of our matrix:\")\n",
    "print(aggregate_collections.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users we removed because they had fewer than 1 highly-rated games:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(\"Users we removed because they had fewer than 1 highly-rated games:\")\n",
    "print(removed_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training Matrix: Split user matrix to inputs and outputs\n",
    "\n",
    "The next step is to isolate each game from each collection. All the other games in the collection become features associated with having a value of \"1\" in that index. In other words, split our matrix into the input matrix (encoded collection) and output (encoded game that appears with the input set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the aggregated collections list\n",
    "aggregate_collections = pd.read_csv('Coded user collections.csv')\n",
    "aggregate_collections.drop(['Unnamed: 0'], inplace=True, axis=1)\n",
    "\n",
    "# Number of games we are considering (from top rated)\n",
    "total = 5000\n",
    "\n",
    "# Get the game_list\n",
    "games_list = pd.read_csv('bgg_id_output.csv')\n",
    "#Remove all NaN rows\n",
    "games_list.dropna(axis=0,how='any',inplace=True)\n",
    "games_list.reset_index(drop=True,inplace=True)\n",
    "#There are repeat titles in the list. Remove them.\n",
    "rep_games_idx = games_list[games_list['Game'].duplicated()].index.tolist() #Returns the indices of all repeat titles. This list does NOT include the first appearance\n",
    "games_list.drop(games_list.index[rep_games_idx],inplace=True)\n",
    "games_list.reset_index(drop=True,inplace=True)\n",
    "#Reduce to # of games to consider\n",
    "games_list = games_list.loc[:total,:]\n",
    "\n",
    "# Get the playerlist\n",
    "playerlist = pd.read_excel('playerlist.xlsx')\n",
    "# Generate the bgg dictionary of indices to game\n",
    "games, games_decode = bgg_dict(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep track of how many training rows we will have\n",
    "total_training_rows = 0\n",
    "\n",
    "#Iterate through all users and convert collections into input vectors and expected_output vectors\n",
    "for i in range(0, aggregate_collections['User'].shape[0]):\n",
    "    #Use generate_training to create the input and expected output vectors\n",
    "    user_input, user_exp_output = generate_training(aggregate_collections.iloc[i,1:].as_matrix(), games)\n",
    "    \n",
    "    #Append vectors into a matrix\n",
    "    if i == 0:\n",
    "        training_data = user_input\n",
    "        exp_output_data = user_exp_output\n",
    "    else:\n",
    "        training_data = np.concatenate((training_data, user_input),axis=0)\n",
    "        exp_output_data = np.concatenate((exp_output_data, user_exp_output), axis=0)\n",
    "    \n",
    "    #Update number of rows generated\n",
    "    total_training_rows = total_training_rows + user_input.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For storage, store input and output stacked vertically in a csv\n",
    "saving = np.concatenate((training_data, exp_output_data), axis=0)\n",
    "saving = pd.DataFrame(saving, columns=list(games_list['Game']))\n",
    "saving.to_csv('Vectorized bgg data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT TRAINING DATA\n",
    "\n",
    "As with training any model, we split our encoded data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of games we are considering (from top rated)\n",
    "total = 5000\n",
    "# Generate the bgg dictionary of indices to game\n",
    "games, games_decode = bgg_dict(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8515, 5001)\n",
      "(8515, 5001)\n"
     ]
    }
   ],
   "source": [
    "# Load vectorized data\n",
    "vectorized = pd.read_csv('Vectorized bgg data.csv')\n",
    "vectorized.drop('Unnamed: 0', axis=1, inplace=True) #Remove unnecessary first column\n",
    "row_size = int(vectorized.shape[0]/2) #The actual total datapoints is half the number of rows\n",
    "\n",
    "# Split the data into the input and expected_output vectors\n",
    "input_data = vectorized.iloc[:row_size,:].as_matrix()\n",
    "exp_output_data = vectorized.iloc[row_size:,:].as_matrix()\n",
    "\n",
    "print(input_data.shape)\n",
    "print(exp_output_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training inputs: (6411, 5001)\n",
      "Training outputs: (6411, 5001)\n",
      "CV inputs: (2138, 5001)\n",
      "CV outputs: (2138, 5001)\n"
     ]
    }
   ],
   "source": [
    "# Divide dataset into Training and Test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Train_inputs, CV_inputs, Train_outputs, CV_outputs = train_test_split(input_data, exp_output_data, test_size=0.25, random_state=101)\n",
    "\n",
    "print('Training inputs: ' + str(Train_inputs.shape))\n",
    "print('Training outputs: ' + str(Train_outputs.shape))\n",
    "print('CV inputs: ' + str(CV_inputs.shape))\n",
    "print('CV outputs: ' + str(CV_outputs.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some extra analysis\n",
    "\n",
    "Before we hop into training, I did some quick qualitative analysis out of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum all the columns of expected_outputs to see how many collections \n",
    "#  include each boardgame\n",
    "mentions = exp_output_data.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Codenames: 77.0\n"
     ]
    }
   ],
   "source": [
    "# Game that appears the most\n",
    "print(games_decode[mentions.argmax()] +': '+ str(mentions.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices of games that are in user collections and \n",
    "#  games that never appear in the user collections\n",
    "not_in_collections_idx = np.where(mentions==0)[0]\n",
    "in_collections_idx = np.nonzero(mentions)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games from the Top 5000 that don't appear in anyone's collections:\n",
      "3160\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of games from the Top 5000 that don't appear in anyone's collections:\")\n",
    "print(len(not_in_collections_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games from the Top 5000 that appear in at least one collection:\n",
      "1841\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of games from the Top 5000 that appear in at least one collection:\")\n",
    "print(len(in_collections_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the top 5000 games, 3168 games are not in any of the user collections. Indices of the games are stored in array not_in_collections_idx."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Models\n",
    "\n",
    "I decided to try two different approaches to implementing CBOW. First, I just tried to use sklearn's Multilayer Perceptron (1 layer neural network) and see how well that would work.\n",
    "\n",
    "Second, since I wanted to try and learn to use TensorFlow, I decided to implement a model through TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black box MultiLayer Perceptron\n",
    "\n",
    "Just try sklearn's MLP regressor...?\n",
    "\n",
    "Inspired by: https://towardsdatascience.com/the-perils-of-predictive-policing-11928a9f1d60\n",
    "\n",
    "http://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "\n",
    "https://en.wikipedia.org/wiki/Limited-memory_BFGS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(300), #1 hidden layer of 300 neurons\n",
    "                    solver = 'lbfgs', #Limited memory BFGS\n",
    "                    max_iter = 300, #Converge by 300 iterations or optimization stops\n",
    "                    random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=300, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=300, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(Train_inputs,Train_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81547340508501009"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate training error\n",
    "mlp.score(Train_inputs, Train_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "from sklearn.externals import joblib\n",
    "filename = 'bgg_rec_mlp.joblib.pkl'\n",
    "_ = joblib.dump(mlp, filename, compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For future use, we can just load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.externals import joblib\n",
    "filename = 'bgg_rec_mlp.joblib.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded_mlp = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81547340508501009"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_mlp.score(Train_inputs, Train_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try checking the CV dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059401309635173059"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_mlp.score(CV_inputs, CV_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the mlp does decently well with the training data set (score = 0.81) whereas it does terribly with the CV data set (score = 0.06)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if there's an affect of different numbers of neurons in the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.externals import joblib\n",
    "from IPython.display import clear_output\n",
    "\n",
    "neurons = [100, 300, 500, 1000]\n",
    "\n",
    "col = ['#Neurons', 'Training Acc', 'CV Acc']\n",
    "#mlp_results = pd.DataFrame(columns=col)\n",
    "\n",
    "for n in neurons:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (n),\n",
    "                       solver = 'lbfgs',\n",
    "                       max_iter = 200,\n",
    "                       random_state = 1)\n",
    "    \n",
    "    mlp.fit(Train_inputs, Train_outputs)\n",
    "    \n",
    "    trained_acc = mlp.score(Train_inputs, Train_outputs)\n",
    "    CV_acc = mlp.score(CV_inputs, CV_outputs)\n",
    "    \n",
    "    mlp_results = mlp_results.append(pd.DataFrame([[n, trained_acc, CV_acc]], columns=col))\n",
    "    \n",
    "    clear_output(wait = True)\n",
    "    print(mlp_results)\n",
    "    \n",
    "    filename = 'bgg_mlp_' + str(n) + 'neurons.joblib.pkl'\n",
    "    _ = joblib.dump(mlp, filename, compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Neurons</th>\n",
       "      <th>Training Acc</th>\n",
       "      <th>CV Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.119482</td>\n",
       "      <td>0.006080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>0.434254</td>\n",
       "      <td>0.018241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>0.433006</td>\n",
       "      <td>0.019177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.670410</td>\n",
       "      <td>0.055192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  #Neurons  Training Acc    CV Acc\n",
       "0      100      0.119482  0.006080\n",
       "0      300      0.434254  0.018241\n",
       "0      500      0.433006  0.019177\n",
       "0     1000      0.670410  0.055192"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also adjust how many iterations we need to converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Iter  Training Acc    CV Acc\n",
      "0  1000      0.000000  0.000000\n",
      "0  1000      0.813914  0.058934\n",
      "0  1000      0.976447  0.063611\n",
      "0  1000      0.999844  0.065014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.externals import joblib\n",
    "from IPython.display import clear_output\n",
    "\n",
    "iter_ct = [100, 300, 500, 1000]\n",
    "\n",
    "col = ['Iter', 'Training Acc', 'CV Acc']\n",
    "mlp_results_iter = pd.DataFrame(columns=col)\n",
    "\n",
    "for i in iter_ct:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (300),\n",
    "                       solver = 'lbfgs',\n",
    "                       max_iter = i,\n",
    "                       random_state = 1)\n",
    "    \n",
    "    mlp.fit(Train_inputs, Train_outputs)\n",
    "    \n",
    "    trained_acc = mlp.score(Train_inputs, Train_outputs)\n",
    "    CV_acc = mlp.score(CV_inputs, CV_outputs)\n",
    "    \n",
    "    mlp_results_iter = mlp_results_iter.append(pd.DataFrame([[i, trained_acc, CV_acc]], columns=col))\n",
    "    \n",
    "    clear_output(wait = True)\n",
    "    print(mlp_results_iter)\n",
    "    \n",
    "    filename = 'bgg_mlp_' + str(i) + 'iter.joblib.pkl'\n",
    "    _ = joblib.dump(mlp, filename, compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was a bug in the previous run so the Iter# is incorrect. Reset it properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "mlp_results_iter['Iter'].loc[:] = [100, 300, 500, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iter</th>\n",
       "      <th>Training Acc</th>\n",
       "      <th>CV Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>0.813914</td>\n",
       "      <td>0.058934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>0.976447</td>\n",
       "      <td>0.063611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.999844</td>\n",
       "      <td>0.065014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Iter  Training Acc    CV Acc\n",
       "0   100      0.000000  0.000000\n",
       "0   300      0.813914  0.058934\n",
       "0   500      0.976447  0.063611\n",
       "0  1000      0.999844  0.065014"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_results_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems more iterations allow the training accuracy to converge and it takes at least 500 to get above 90% accuracy. However, the CV accuracy seems to converge with 300 iteration cap whereas increasing number of neurons can increase the CV accuracy.\n",
    "\n",
    "Let's try a 1000 neuron and 1500 neuron combo with 1000 iteration-cap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  #Neurons  Training Acc    CV Acc\n",
      "0     1000      0.999844  0.080917\n",
      "0     1500      0.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.externals import joblib\n",
    "from IPython.display import clear_output\n",
    "\n",
    "neurons = [1000, 1500]\n",
    "\n",
    "col = ['#Neurons', 'Training Acc', 'CV Acc']\n",
    "mlp_results = pd.DataFrame(columns=col)\n",
    "\n",
    "for n in neurons:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (n),\n",
    "                       solver = 'lbfgs',\n",
    "                       max_iter = 1000,\n",
    "                       random_state = 1)\n",
    "    \n",
    "    mlp.fit(Train_inputs, Train_outputs)\n",
    "    \n",
    "    trained_acc = mlp.score(Train_inputs, Train_outputs)\n",
    "    CV_acc = mlp.score(CV_inputs, CV_outputs)\n",
    "    \n",
    "    mlp_results = mlp_results.append(pd.DataFrame([[n, trained_acc, CV_acc]], columns=col))\n",
    "    \n",
    "    clear_output(wait = True)\n",
    "    print(mlp_results)\n",
    "    \n",
    "    filename = 'bgg_mlp_' + str(n) + 'neurons_1000iter.joblib.pkl'\n",
    "    _ = joblib.dump(mlp, filename, compress=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  #Neurons  Training Acc  CV Acc\n",
      "0     1500           0.0     0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.externals import joblib\n",
    "from IPython.display import clear_output\n",
    "\n",
    "neurons = [1500]\n",
    "\n",
    "col = ['#Neurons', 'Training Acc', 'CV Acc']\n",
    "mlp_results = pd.DataFrame(columns=col)\n",
    "\n",
    "for n in neurons:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes = (1500),\n",
    "                       solver = 'lbfgs',\n",
    "                       max_iter = 1000,\n",
    "                       random_state = 1)\n",
    "    \n",
    "    mlp.fit(Train_inputs, Train_outputs)\n",
    "    \n",
    "    trained_acc = mlp.score(Train_inputs, Train_outputs)\n",
    "    CV_acc = mlp.score(CV_inputs, CV_outputs)\n",
    "    \n",
    "    mlp_results = mlp_results.append(pd.DataFrame([[n, trained_acc, CV_acc]], columns=col))\n",
    "    \n",
    "    #clear_output(wait = True)\n",
    "    print(mlp_results)\n",
    "    \n",
    "    #filename = 'bgg_mlp_' + str(n) + 'neurons_1000iter.joblib.pkl'\n",
    "    #_ = joblib.dump(mlp, filename, compress=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like with the scikit learn mlp, 1000 neurons with 1000 iterations performs great on Training but still has very low CV accuracy. The model is essentially overfitting the Training data set.\n",
    "\n",
    "Furthermore, it looks like above 1000 neurons in the hidden layer, the model falls apart.\n",
    "\n",
    "To try and account for overfitting, we can either obtain more training examples (which is not trivial) or reduce the number of features (which is possible; there are 1833 games in the top 5000 games that don't even show up in any collection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec and Tensorflow implementation\n",
    "\n",
    "https://www.tensorflow.org/tutorials/word2vec\n",
    "\n",
    "http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/\n",
    "\n",
    "https://stackoverflow.com/questions/37394970/tensorflow-word2vec-cbow-model\n",
    "\n",
    "https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
    "\n",
    "As in examples of word2vec implementation, we have created a \"one-hot\" vector where each unique integer value (index) is assigned to a specific boardgame. We have the dictionary required to encode and decode boardgame collections and the corresponding output. And we already have our dataset with both collection inputs and the expected outputs for training.\n",
    "\n",
    "Word2vec only has 1 hidden layer: a word embedding matrix.\n",
    "\n",
    "The output layer uses the softmax function\n",
    "\n",
    "https://gist.github.com/discorev/b6a0900a52b62cd04f33\n",
    "\n",
    "https://gist.github.com/yxtay/a94d971955d901c4690129580a4eafb9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "http://adventuresinmachinelearning.com/python-tensorflow-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Python optimization variables\n",
    "learning_rate = 0.5\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "# Training data placeholders\n",
    "#input x will be an unknown # of training examples encoded as a vectors of length 13955 (boardgames)\n",
    "x = tf.placeholder(tf.float32, [None, 13955]) \n",
    "#output placeholder will be # of predictions encoded as vectors of length 13955 (boardgames)\n",
    "y = tf.placeholder(tf.float32, [None, 13955])\n",
    "\n",
    "#weights connecting input to hidden layer\n",
    "# tf.random_normal will generate values from a mean=0 and stddev=input\n",
    "W1 = tf.Variable(tf.random_normal([13955,300], stddev=0.03), name = 'W1') #300 Neuronal layer\n",
    "b1 = tf.Variable(tf.random_normal([300]), name = 'b1') #First layer bias\n",
    "\n",
    "#weights connecting hidden layer to output layer\n",
    "W2 = tf.Variable(tf.random_normal([300,13955],stddev=0.03), name = 'W2') #Convert back to 13955 output\n",
    "b2 = tf.Variable(tf.random_normal([13955]), name = 'b2') #Second layer bias\n",
    "\n",
    "\n",
    "# Calculations for the hidden layer\n",
    "hidden_out = tf.add(tf.matmul(x, W1),b1) #matrix multiply x and W1 weights, add b1 bias\n",
    "hidden_out = tf.nn.relu(hidden_out) #rectified linear unit activation function: converts all negative values to 0\n",
    "\n",
    "# Calculate output layer with softmax\n",
    "y_ = tf.nn.softmax(tf.add(tf.matmul(hidden_out, W2), b2)) #apply softmax after matrix multiply hidden layer output and W2 weights, and adding b2 bias\n",
    "\n",
    "\n",
    "# Cost function: Cross Entropy\n",
    "y_clipped = tf.clip_by_value(y_, 1e-10, 0.9999999) #Limits output values between 1e-10 and 0.9999999; prevents log(0) operations\n",
    "cross_entropy = -tf.reduce_mean(tf.reduce_sum(y * tf.log(y_clipped) \n",
    "                                              + (1-y) * tf.log(1 - y_clipped), axis=1))\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cross_entropy)\n",
    "#optimizer will minimize the cross entropy cost function and use the learning rate we set (0.5) as learning rate alpha\n",
    "\n",
    "# Initialization operator\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# Define an accuracy assessment operation\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_, 1)) #Checks that predicted output is same as predicted\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) #Changes boolean correct_prediction to float, then finds mean. 1 = highest accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Start tensorflow session\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # initialize the variables\n",
    "    sess.run(init_op)\n",
    "    total_batch = int(len(<training labels>) / batch_size) #Use data set\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        avg_cost = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = <training group.nextbatch(batch_size=batch_size) #Use data set\n",
    "            _, c = sess.run(optimizer, cross_entropy],\n",
    "                           feed_dict = {x: batch_x, y: batch_y})\n",
    "            avg_cost += c / total_batch\n",
    "        \n",
    "        print(\"Epoch: \", (epoch + 1), \"cost = \", \"{:.3f}\".format(avg_cost))\n",
    "        \n",
    "    print(sess.run(accuracy, feed_dict={x: <training group decoded>, y:<training group coded>})) #Use data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Implementing Tensorflow Model\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/learn-word2vec-by-implementing-it-in-tensorflow-45641adaf2ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training inputs: (5984, 5001)\n",
      "Training outputs: (5984, 5001)\n",
      "CV inputs: (2565, 5001)\n",
      "CV outputs: (2565, 5001)\n"
     ]
    }
   ],
   "source": [
    "print('Training inputs: ' + str(Train_inputs.shape))\n",
    "print('Training outputs: ' + str(Train_outputs.shape))\n",
    "print('CV inputs: ' + str(CV_inputs.shape))\n",
    "print('CV outputs: ' + str(CV_outputs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5001"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games\n",
    "len(games_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NEW VERSION\n",
    "#Create tensorflow variables\n",
    "\n",
    "# Make placeholders for x_train and y_train (x = data points, y = expected labels)\n",
    "#Create placeholder architecture. shape = (None, len(games)) generates a matrix with unknown number of rows and len(games) columns\n",
    "#This is the same as the representation of our data in vector form, with each individual example taking a row\n",
    "\n",
    "batch_size = Train_inputs.shape[0]\n",
    "col_size = len(games)\n",
    "num_sampled = 30 #Number of negative examples to sample\n",
    "EMBEDDING_DIM = 150 #Hyperparameter to be adjusted; # neurons of the hidden layer\n",
    "\n",
    "\n",
    "def gamegram():\n",
    "    x = tf.placeholder(tf.float32, shape = [batch_size, None])\n",
    "    y_label = tf.placeholder(tf.int32, shape=[batch_size, None])\n",
    "    #val_data = tf.constant(val_data,dtype=tf.int32)\n",
    "\n",
    "    with tf.variable_scope(\"gamegram\") as scope:\n",
    "        embeddings = tf.Variable(tf.random_uniform([col_size,\n",
    "                                                   EMBEDDING_DIM],\n",
    "                                                  -1.0, 1.0))\n",
    "        batch_embeddings = tf.nn.embedding_lookup(embeddings, tf.cast(x,tf.int32))\n",
    "\n",
    "        weights = tf.Variable(tf.truncated_normal([col_size,\n",
    "                                                  EMBEDDING_DIM],\n",
    "                                                  stddev = 1.0/math.sqrt(EMBEDDING_DIM)))\n",
    "        biases = tf.Variable(tf.zeros(col_size))\n",
    "\n",
    "        loss = tf.reduce_mean(tf.nn.nce_loss(weights = weights,\n",
    "                                            biases = biases,\n",
    "                                            labels = y_label,\n",
    "                                            inputs = x,\n",
    "                                            num_sampled = num_sampled,\n",
    "                                            num_classes = col_size,\n",
    "                                            num_true = col_size))\n",
    "\n",
    "        norm = tf.sqrt(tf.reduce_mean(tf.square(embeddings), 1, keep_dims = True))\n",
    "\n",
    "        normalized_embeddings = embeddings/norm\n",
    "        \n",
    "#        val_embeddings = tf.nn.embedding_lookup(normalized_embeddings, val_dataset)\n",
    "#        similarity = tf.matmul(val_embeddings, normalized_embeddings, transpose_b=True)\n",
    "    \n",
    "        return x, y_label, normalized_embeddings, loss #, similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    n_iters = 100\n",
    "    \n",
    "    x, y_label, normalized_embeddings, loss = gamegram()\n",
    "    #    inputs, labels, normalized_embeddings, loss, similarity = gamegram()\n",
    "    optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        average_loss = 0.0\n",
    "        \n",
    "        # train for n_iter iterations\n",
    "        #Recall: x = Train_inputs, y_label = Train_outputs\n",
    "        for _ in range(n_iters):\n",
    "            feed_dict = {x: Train_inputs, y_label: Train_outputs}\n",
    "            _, loss_val = sess.run([optimizer, loss], feed_dict)\n",
    "            average_loss += loss_val\n",
    "\n",
    "            if step %1000 == 0:\n",
    "                if step > 0:\n",
    "                    average_loss /= 1000\n",
    "                print('loss at iter', step, ':', average_loss)\n",
    "                average_loss = 0        \n",
    "\n",
    "        final_embeddings = normalized_embedding.eval()\n",
    "        return final_embeddings\n",
    "                    \n",
    "#         for step, batch_data in enumerate(train_data): #need to change\n",
    "#            # inputs, labels = batch_data #need to change\n",
    "#            # feed_dict = {batch_inputs: inputs, batch_labels: labels}\n",
    "            \n",
    "#             _, loss_val = session.run([optimizer, loss], feed_dict)\n",
    "#             average_loss += loss_val\n",
    "            \n",
    "#             if step %1000 == 0:\n",
    "#                 if step > 0:\n",
    "#                     average_loss /= 1000\n",
    "#                 print('loss at iter', step, ':', average_loss)\n",
    "#                 average_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_embeddings = run()\n",
    "\n",
    "#visualize_embeddings(final_embeddings, games_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create tensorflow variables\n",
    "\n",
    "# Make placeholders for x_train and y_train (x = data points, y = expected labels)\n",
    "#Create placeholder architecture. shape = (None, len(games)) generates a matrix with unknown number of rows and len(games) columns\n",
    "#This is the same as the representation of our data in vector form, with each individual example taking a row\n",
    "\n",
    "x = tf.placeholder(tf.int32, shape = (None, len(games)))\n",
    "y_label = tf.placeholder(tf.int32, shape=(None, len(games)))\n",
    "\n",
    "\n",
    "# Hidden layer calculation\n",
    "EMBEDDING_DIM = 700 #Hyperparameter to be adjusted; # neurons of the hidden layer\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([len(games), EMBEDDING_DIM])) #Weights\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([EMBEDDING_DIM])) #bias\n",
    "\n",
    "hidden_representation = tf.add(tf.matmul(x,W1), b1) # x * W1 + b\n",
    "\n",
    "# Output layer calculation\n",
    "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, len(games)])) #Weights\n",
    "\n",
    "b2 = tf.Variable(tf.random_normal([len(games)]))\n",
    "\n",
    "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_representation,W2), b2))\n",
    "#Apply softmax: Converts to normalized probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(501), Dimension(700)])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-44.917133"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess.run(init) #make sure you do this!\n",
    "\n",
    "#cross_entropy_loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), reduction_indices=[1]))\n",
    "cross_entropy_loss = tf.reduce_mean(tf.reduce_sum(y_label * tf.log(prediction + 1e-10) + (1-y_label) * tf.log(1 - prediction + 1e-10), axis=1))\n",
    "sess.run(cross_entropy_loss, feed_dict={x: Train_inputs, y_label:Train_outputs})\n",
    "\n",
    "#Added +1e-10 to softmax predictions to try and handle NaN cases. It seems super small values get cut out; happens with extremely sparse matrices.\n",
    "#https://stackoverflow.com/questions/39583752/nan-from-sparse-softmax-cross-entropy-with-logits-in-tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is :  22.961\n",
      "loss is :  22.9602\n",
      "loss is :  22.9594\n",
      "loss is :  22.9587\n",
      "loss is :  22.958\n",
      "loss is :  22.9575\n",
      "loss is :  22.9572\n",
      "loss is :  22.9571\n",
      "loss is :  22.957\n",
      "loss is :  22.9569\n",
      "loss is :  22.9568\n",
      "loss is :  22.9567\n",
      "loss is :  22.9566\n",
      "loss is :  22.9565\n",
      "loss is :  22.9564\n",
      "loss is :  22.9561\n",
      "loss is :  22.9557\n",
      "loss is :  22.9552\n",
      "loss is :  22.9546\n",
      "loss is :  22.9541\n",
      "loss is :  22.9536\n",
      "loss is :  22.9528\n",
      "loss is :  22.9518\n",
      "loss is :  22.9506\n",
      "loss is :  22.9494\n",
      "loss is :  22.9482\n",
      "loss is :  22.9472\n",
      "loss is :  22.9463\n",
      "loss is :  22.9456\n",
      "loss is :  22.9452\n",
      "loss is :  22.9451\n",
      "loss is :  22.9451\n",
      "loss is :  22.9451\n",
      "loss is :  22.9451\n",
      "loss is :  22.9451\n",
      "loss is :  22.9451\n",
      "loss is :  22.945\n",
      "loss is :  22.945\n",
      "loss is :  22.945\n",
      "loss is :  22.945\n",
      "loss is :  22.945\n",
      "loss is :  22.945\n",
      "loss is :  22.945\n",
      "loss is :  22.945\n",
      "loss is :  22.945\n",
      "loss is :  22.945\n",
      "loss is :  22.945\n",
      "loss is :  22.945\n",
      "loss is :  22.945\n",
      "loss is :  22.945\n",
      "loss is :  22.9448\n",
      "loss is :  22.9438\n",
      "loss is :  22.9418\n",
      "loss is :  22.9399\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n",
      "loss is :  22.9393\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess.run(init) #make sure you do this!\n",
    "\n",
    "# Define loss function: Cross Entropy Loss function\n",
    "cross_entropy_loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction + 1e-10), reduction_indices=[1]))\n",
    "# Define training step\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy_loss)\n",
    "\n",
    "n_iters = 100\n",
    "\n",
    "# train for n_iter iterations\n",
    "#Recall: x = Train_inputs, y_label = Train_outputs\n",
    "for _ in range(n_iters):\n",
    "    sess.run(train_step, feed_dict={x: Train_inputs, y_label: Train_outputs})\n",
    "    print('loss is : ', sess.run(cross_entropy_loss, feed_dict={x: Train_inputs, y_label: Train_outputs}))    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "With all games in the vector and 700 hidden neurons, loss is about 23\n",
    "With top 5000 games in the vector and 700 hidden neurons, loss is about 23.0141\n",
    "With top 500 games in the vector and 700 hidden neurons, loss is about 22.9393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1775: Rebellion': 220,\n",
       " '1830: Railways & Robber Barons': 148,\n",
       " '1960: The Making of the President': 140,\n",
       " '1989: Dawn of Freedom': 337,\n",
       " '51st State: Master Set': 256,\n",
       " '7 Wonders': 37,\n",
       " '7 Wonders Duel': 8,\n",
       " 'A Feast for Odin': 35,\n",
       " 'A Few Acres of Snow': 207,\n",
       " 'A Game of Thrones (first edition)': 281,\n",
       " 'A Game of Thrones: The Board Game (Second Edition)': 73,\n",
       " 'A Game of Thrones: The Card Game (Second Edition)': 254,\n",
       " 'Above and Below': 126,\n",
       " 'Abyss': 301,\n",
       " 'Acquire': 185,\n",
       " 'Advanced Squad Leader': 171,\n",
       " 'Advanced Squad Leader: Starter Kit #1': 360,\n",
       " \"Aeon's End\": 375,\n",
       " 'Age of Empires III: The Age of Discovery': 116,\n",
       " 'Age of Industry': 397,\n",
       " 'Age of Steam': 94,\n",
       " 'Agricola': 14,\n",
       " 'Agricola (revised edition)': 291,\n",
       " 'Agricola: All Creatures Big and Small': 153,\n",
       " 'Airlines Europe': 267,\n",
       " 'Alchemists': 74,\n",
       " 'Alhambra': 381,\n",
       " 'Alien Frontiers': 132,\n",
       " 'Amerigo': 250,\n",
       " 'Among the Stars': 378,\n",
       " 'Amun-Re': 235,\n",
       " 'Anachrony': 139,\n",
       " 'Android: Netrunner': 31,\n",
       " 'Antiquity': 227,\n",
       " 'AquaSphere': 311,\n",
       " 'Arboretum': 341,\n",
       " 'Arcadia Quest': 72,\n",
       " 'Archipelago': 253,\n",
       " 'Argent: The Consortium': 429,\n",
       " 'Arkham Horror': 205,\n",
       " 'Arkham Horror: The Card Game': 19,\n",
       " 'Ascension: Deckbuilding Game': 466,\n",
       " 'Ascension: Return of the Fallen': 498,\n",
       " 'Ascension: Storm of Souls': 470,\n",
       " 'Ashes: Rise of the Phoenixborn': 328,\n",
       " 'At the Gates of Loyang': 212,\n",
       " 'Automobile': 288,\n",
       " 'BANG! The Dice Game': 440,\n",
       " 'Baseball Highlights: 2045': 359,\n",
       " 'Battle Line': 161,\n",
       " 'BattleCON: Devastation of Indines': 168,\n",
       " 'BattleLore': 215,\n",
       " 'BattleLore (Second Edition)': 117,\n",
       " 'Battlestar Galactica': 53,\n",
       " 'Belfort': 323,\n",
       " 'Betrayal at House on the Hill': 362,\n",
       " 'Between Two Cities': 458,\n",
       " 'Biblios': 266,\n",
       " 'Blokus': 484,\n",
       " 'Blood Bowl (Third Edition)': 217,\n",
       " 'Blood Bowl: Living Rulebook': 163,\n",
       " 'Blood Bowl: Team Manager  The Card Game': 209,\n",
       " 'Blood Rage': 16,\n",
       " 'Blue Moon City': 464,\n",
       " 'Bohnanza': 348,\n",
       " 'Bora Bora': 130,\n",
       " 'Brass: Lancashire': 28,\n",
       " 'Brew Crafters': 427,\n",
       " 'Bridge': 447,\n",
       " 'Britannia': 490,\n",
       " 'Broom Service': 400,\n",
       " 'Bruges': 172,\n",
       " 'Bruxelles 1893': 241,\n",
       " 'Burgle Bros.': 211,\n",
       " 'CO': 489,\n",
       " \"Ca$h 'n Guns (Second Edition)\": 448,\n",
       " 'Cacao': 493,\n",
       " 'Camel Up': 356,\n",
       " 'Captain Sonar': 91,\n",
       " 'Carcassonne': 127,\n",
       " 'Carcassonne: Hunters and Gatherers': 364,\n",
       " 'Carcassonne: The Castle': 460,\n",
       " 'Carcassonne: The City': 465,\n",
       " 'Carson City': 298,\n",
       " 'Castles of Mad King Ludwig': 66,\n",
       " 'Catan': 249,\n",
       " 'Caverna: The Cave Farmers': 10,\n",
       " 'Caylus': 39,\n",
       " 'Century: Spice Road': 308,\n",
       " 'Champions of Midgard': 159,\n",
       " 'Chaos in the Old World': 84,\n",
       " 'Chess': 396,\n",
       " 'Chicago Express': 339,\n",
       " 'Chinatown': 345,\n",
       " 'Churchill': 497,\n",
       " 'Citadels': 293,\n",
       " 'Civilization': 196,\n",
       " 'Clank!: A Deck-Building Adventure': 54,\n",
       " 'Clash of Cultures': 174,\n",
       " 'Claustrophobia': 162,\n",
       " 'Coal Baron': 449,\n",
       " 'Codenames': 34,\n",
       " 'Codenames: Pictures': 167,\n",
       " 'Coloretto': 454,\n",
       " 'Colosseum': 338,\n",
       " 'Colt Express': 269,\n",
       " 'Combat Commander: Europe': 88,\n",
       " 'Combat Commander: Pacific': 368,\n",
       " 'Commands & Colors: Ancients': 81,\n",
       " 'Commands & Colors: Napoleonics': 263,\n",
       " 'Conan': 371,\n",
       " 'Concordia': 30,\n",
       " 'Conflict of Heroes: Awakening the Bear! (second edition)': 431,\n",
       " 'Conflict of Heroes: Awakening the Bear!  Russia 1941-42': 336,\n",
       " 'Core Worlds': 467,\n",
       " 'Cosmic Encounter': 87,\n",
       " 'Coup': 330,\n",
       " 'Crokinole': 65,\n",
       " 'Cry Havoc': 313,\n",
       " 'Cthulhu Wars': 208,\n",
       " 'Cuba': 376,\n",
       " 'Cuba Libre': 451,\n",
       " 'Cyclades': 120,\n",
       " 'D-Day at Omaha Beach': 456,\n",
       " 'DVONN': 324,\n",
       " 'Dead of Winter: A Crossroads Game': 44,\n",
       " 'Dead of Winter: The Long Night': 143,\n",
       " 'Deception: Murder in Hong Kong': 180,\n",
       " 'Defenders of the Realm': 320,\n",
       " 'Descent: Journeys in the Dark': 240,\n",
       " 'Descent: Journeys in the Dark (Second Edition)': 64,\n",
       " 'Deus': 276,\n",
       " 'Die Macher': 156,\n",
       " 'Diplomacy': 468,\n",
       " 'Discworld: Ankh-Morpork': 388,\n",
       " 'Dixit': 166,\n",
       " 'Dixit Odyssey': 137,\n",
       " 'Dixit: Journey': 322,\n",
       " 'Dominant Species': 45,\n",
       " 'Dominion': 57,\n",
       " 'Dominion: Intrigue': 50,\n",
       " 'Dune': 189,\n",
       " 'Dungeon Lords': 157,\n",
       " 'Dungeon Petz': 115,\n",
       " 'Dungeons & Dragons: The Legend of Drizzt Board Game': 417,\n",
       " 'Dungeons & Dragons: Wrath of Ashardalon Board Game': 483,\n",
       " 'Earth Reborn': 223,\n",
       " 'Eclipse': 23,\n",
       " 'Egizia': 251,\n",
       " 'El Grande': 49,\n",
       " 'Elder Sign': 441,\n",
       " 'Eldritch Horror': 41,\n",
       " 'Elysium': 285,\n",
       " 'Eminent Domain': 389,\n",
       " 'Empires: Age of Discovery': 478,\n",
       " 'Endeavor': 175,\n",
       " 'Escape: The Curse of the Temple': 372,\n",
       " 'Ethnos': 404,\n",
       " 'Euphoria: Build a Better Dystopia': 287,\n",
       " 'Evolution': 299,\n",
       " 'Evolution: Climate': 279,\n",
       " 'Fields of Arle': 52,\n",
       " 'Finca': 495,\n",
       " 'Fire in the Lake': 353,\n",
       " 'Firefly: The Game': 255,\n",
       " 'First Class': 399,\n",
       " 'Five Tribes': 47,\n",
       " 'Flash Point: Fire Rescue': 237,\n",
       " \"Flick 'em Up!\": 472,\n",
       " 'Food Chain Magnate': 24,\n",
       " 'For Sale': 244,\n",
       " 'Forbidden Desert': 232,\n",
       " 'Forbidden Stars': 78,\n",
       " 'Formula D': 411,\n",
       " 'Francis Drake': 304,\n",
       " 'Freedom: The Underground Railroad': 289,\n",
       " 'Fresco': 221,\n",
       " 'Friday': 277,\n",
       " 'Friedrich': 418,\n",
       " 'Fury of Dracula (second edition)': 357,\n",
       " 'Fury of Dracula (third edition)': 145,\n",
       " 'Galaxy Trucker': 111,\n",
       " 'Gears of War: The Board Game': 314,\n",
       " 'Genoa': 450,\n",
       " 'Ghost Stories': 173,\n",
       " 'Ginkgopolis': 297,\n",
       " 'Glass Road': 190,\n",
       " 'Glen More': 233,\n",
       " 'Gloomhaven': 3,\n",
       " 'Glory to Rome': 129,\n",
       " 'Go': 104,\n",
       " 'Goa': 90,\n",
       " 'Grand Austria Hotel': 124,\n",
       " 'Great Western Trail': 13,\n",
       " 'Hammer of the Scots': 265,\n",
       " 'Hanabi': 246,\n",
       " 'Hannibal: Rome vs. Carthage': 112,\n",
       " 'Hansa Teutonica': 97,\n",
       " 'Harry Potter: Hogwarts Battle': 383,\n",
       " 'Hawaii': 479,\n",
       " 'Here I Stand': 144,\n",
       " 'Hero Realms': 230,\n",
       " 'Heroscape Master Set: Rise of the Valkyrie': 242,\n",
       " 'Heroscape Master Set: Swarm of the Marro': 436,\n",
       " 'Hive': 179,\n",
       " 'Homesteaders': 443,\n",
       " 'Hyperborea': 488,\n",
       " 'Imhotep': 335,\n",
       " 'Imperial': 118,\n",
       " 'Imperial 2030': 150,\n",
       " 'Imperial Settlers': 107,\n",
       " 'In the Year of the Dragon': 191,\n",
       " 'Indonesia': 187,\n",
       " 'Ingenious': 305,\n",
       " 'Inis': 158,\n",
       " 'Innovation': 257,\n",
       " 'Isle of Skye: From Chieftain to King': 135,\n",
       " 'Istanbul': 86,\n",
       " 'Jaipur': 93,\n",
       " 'Jamaica': 394,\n",
       " 'Jambo': 452,\n",
       " 'K2': 420,\n",
       " 'Kanban: Automotive Revolution': 199,\n",
       " 'Karuba': 363,\n",
       " 'Kemet': 67,\n",
       " 'Keyflower': 36,\n",
       " 'King of New York': 354,\n",
       " 'King of Tokyo': 195,\n",
       " 'Kingdom Builder': 423,\n",
       " 'Kingdom Death: Monster': 155,\n",
       " 'Kingdomino': 216,\n",
       " 'Kingsburg': 245,\n",
       " 'La Granja': 95,\n",
       " 'Labyrinth: The War on Terror, 2001  ?': 268,\n",
       " 'Lancaster': 219,\n",
       " 'Las Vegas': 494,\n",
       " 'Last Night on Earth: The Zombie Game': 487,\n",
       " 'Last Will': 296,\n",
       " 'Le Havre': 29,\n",
       " 'Legacy: The Testament of Duke de Crecy': 476,\n",
       " 'Legendary Encounters: An Alien Deck Building Game': 75,\n",
       " 'Legendary: A Marvel Deck Building Game': 105,\n",
       " 'Legendary: Villains  A Marvel Deck Building Game': 409,\n",
       " 'Legends of Andor': 261,\n",
       " 'Letters from Whitechapel': 164,\n",
       " 'Lewis & Clark': 113,\n",
       " 'Libertalia': 270,\n",
       " 'London': 234,\n",
       " 'Lord of the Rings: The Confrontation': 228,\n",
       " 'Lords of Vegas': 333,\n",
       " 'Lords of Waterdeep': 43,\n",
       " 'Lords of Xidit': 474,\n",
       " 'Lorenzo il Magnifico': 294,\n",
       " 'Lost Cities': 275,\n",
       " 'Louis XIV': 482,\n",
       " 'Love Letter': 177,\n",
       " 'Love Letter: Batman': 403,\n",
       " 'Luna': 366,\n",
       " 'Macao': 210,\n",
       " 'Madeira': 290,\n",
       " 'Mage Knight Board Game': 15,\n",
       " 'Mage Wars Arena': 108,\n",
       " 'Magic: The Gathering': 147,\n",
       " 'Maharaja: The Game of Palace Building in India': 462,\n",
       " 'Mansions of Madness': 224,\n",
       " 'Mansions of Madness: Second Edition': 20,\n",
       " 'Mare Nostrum: Empires': 398,\n",
       " 'Maria': 225,\n",
       " 'Marvel Dice Masters: Avengers vs. X-Men': 355,\n",
       " 'Marvel Dice Masters: Uncanny X-Men': 412,\n",
       " 'Mechs vs. Minions': 21,\n",
       " 'Medici': 419,\n",
       " \"Memoir '44\": 106,\n",
       " 'Merchants & Marauders': 176,\n",
       " 'Mexica': 496,\n",
       " 'Mice and Mystics': 170,\n",
       " 'Middle-Earth Quest': 391,\n",
       " 'Millennium Blades': 280,\n",
       " 'Mission: Red Planet (Second Edition)': 169,\n",
       " 'Modern Art': 218,\n",
       " 'Mombasa': 56,\n",
       " 'Mr. Jack': 385,\n",
       " 'Myrmes': 379,\n",
       " 'Mysterium': 128,\n",
       " 'Mystic Vale': 408,\n",
       " \"Napoleon's Triumph\": 332,\n",
       " 'Nations': 79,\n",
       " 'Navegador': 138,\n",
       " 'Near and Far': 317,\n",
       " 'Neuroshima Hex!': 183,\n",
       " 'Nexus Ops': 306,\n",
       " 'Nippon': 229,\n",
       " 'No Thanks!': 386,\n",
       " 'Notre Dame': 184,\n",
       " 'One Night Ultimate Werewolf': 213,\n",
       " 'One Night Ultimate Werewolf Daybreak': 342,\n",
       " 'Onirim (second edition)': 434,\n",
       " 'Onitama': 192,\n",
       " 'Ora et Labora': 76,\n",
       " 'Orlans': 25,\n",
       " 'Panamax': 437,\n",
       " 'Pandemic': 62,\n",
       " 'Pandemic Iberia': 125,\n",
       " 'Pandemic Legacy: Season 1': 0,\n",
       " 'Pandemic: Reign of Cthulhu': 316,\n",
       " 'Pandemic: The Cure': 238,\n",
       " 'Paperback': 271,\n",
       " 'Patchwork': 46,\n",
       " 'Pathfinder Adventure Card Game: Rise of the Runelords  Base Set': 247,\n",
       " 'Paths of Glory': 85,\n",
       " 'Pax Porfiriana': 346,\n",
       " 'PitchCar': 303,\n",
       " 'Polis: Fight for the Hegemony': 457,\n",
       " 'Port Royal': 413,\n",
       " 'Potion Explosion': 446,\n",
       " 'Power Grid': 22,\n",
       " 'Power Grid Deluxe: Europe/North America': 142,\n",
       " 'Puerto Rico': 11,\n",
       " 'Quadropolis': 214,\n",
       " 'Quantum': 344,\n",
       " 'Ra': 122,\n",
       " 'Race for the Galaxy': 42,\n",
       " 'Raiders of the North Sea': 282,\n",
       " 'Railways of the World': 82,\n",
       " 'Raptor': 365,\n",
       " 'Reef Encounter': 442,\n",
       " 'Risk Legacy': 193,\n",
       " 'Roads & Boats': 231,\n",
       " 'Robinson Crusoe: Adventures on the Cursed Island': 26,\n",
       " 'RoboRally': 309,\n",
       " 'Rococo': 181,\n",
       " 'Roll Player': 492,\n",
       " 'Roll for the Galaxy': 48,\n",
       " 'Runebound (Third Edition)': 453,\n",
       " 'Runewars': 121,\n",
       " 'Russian Railroads': 58,\n",
       " 'Sagrada': 469,\n",
       " 'Saint Petersburg': 202,\n",
       " 'Saint Petersburg (second edition)': 455,\n",
       " 'Samurai': 154,\n",
       " 'San Juan': 201,\n",
       " 'San Juan (second edition)': 274,\n",
       " 'San Marco': 473,\n",
       " 'Santiago': 475,\n",
       " 'Santorini': 63,\n",
       " 'Schotten Totten': 373,\n",
       " 'Scythe': 7,\n",
       " 'Seasons': 134,\n",
       " 'Secret Hitler': 236,\n",
       " 'Sekigahara: The Unification of Japan': 133,\n",
       " 'Sentinels of the Multiverse': 239,\n",
       " 'Shadows of Brimstone: City of the Ancients': 252,\n",
       " 'Shadows of Brimstone: Swamps of Death': 369,\n",
       " 'Shadows over Camelot': 302,\n",
       " 'Shakespeare': 416,\n",
       " 'Sheriff of Nottingham': 200,\n",
       " 'Sherlock Holmes Consulting Detective: The Thames Murders & Other Cases': 55,\n",
       " 'Shipyard': 402,\n",
       " 'Shogun': 110,\n",
       " \"Sid Meier's Civilization: The Board Game\": 146,\n",
       " 'Skull': 463,\n",
       " 'Small World': 160,\n",
       " 'Small World Underground': 248,\n",
       " 'Smash Up: Awesome Level 9000': 321,\n",
       " 'Smash Up: Science Fiction Double Feature': 432,\n",
       " 'Snowdonia': 319,\n",
       " 'Space Alert': 123,\n",
       " 'Space Empires: 4X': 438,\n",
       " 'Space Hulk': 392,\n",
       " 'Space Hulk (third edition)': 188,\n",
       " 'Space Hulk: Death Angel  The Card Game': 500,\n",
       " 'Spartacus: A Game of Blood & Treachery': 260,\n",
       " 'Specter Ops': 343,\n",
       " 'Splendor': 99,\n",
       " 'Spyfall': 318,\n",
       " 'Spyrium': 445,\n",
       " 'Squad Leader': 439,\n",
       " 'Star Realms': 77,\n",
       " 'Star Realms: Colony Wars': 197,\n",
       " 'Star Trek: Fleet Captains': 347,\n",
       " 'Star Wars: Armada': 165,\n",
       " 'Star Wars: Destiny': 243,\n",
       " 'Star Wars: Imperial Assault': 18,\n",
       " 'Star Wars: Rebellion': 4,\n",
       " 'Star Wars: The Card Game': 390,\n",
       " \"Star Wars: The Queen's Gambit\": 485,\n",
       " 'Star Wars: X-Wing Miniatures Game': 51,\n",
       " 'Star Wars: X-Wing Miniatures Game  The Force Awakens Core Set': 258,\n",
       " 'StarCraft: The Board Game': 315,\n",
       " 'Steam': 89,\n",
       " 'Steampunk Rally': 395,\n",
       " 'Stockpile': 286,\n",
       " 'Stone Age': 71,\n",
       " 'Stronghold': 486,\n",
       " 'Struggle of Empires': 292,\n",
       " 'Suburbia': 80,\n",
       " 'Summoner Wars': 329,\n",
       " 'Summoner Wars: Alliances Master Set': 433,\n",
       " 'Summoner Wars: Guild Dwarves vs Cave Goblins': 387,\n",
       " 'Summoner Wars: Master Set': 114,\n",
       " 'Summoner Wars: Phoenix Elves vs Tundra Orcs': 382,\n",
       " 'Super Motherload': 481,\n",
       " 'Survive: Escape from Atlantis!': 203,\n",
       " 'Sushi Go Party!': 136,\n",
       " 'Sushi Go!': 312,\n",
       " 'T.I.M.E Stories': 33,\n",
       " 'TZAAR': 326,\n",
       " 'Taj Mahal': 273,\n",
       " 'Tajemnicze Domostwo': 351,\n",
       " 'Takenoko': 182,\n",
       " 'Tales of the Arabian Nights': 283,\n",
       " 'Taluva': 393,\n",
       " 'Targi': 131,\n",
       " 'Tash-Kalar: Arena of Legends': 425,\n",
       " 'Telestrations': 198,\n",
       " 'Terra Mystica': 5,\n",
       " 'Terraforming Mars': 6,\n",
       " 'The 7th Continent': 149,\n",
       " 'The Battle of Five Armies': 358,\n",
       " 'The Castles of Burgundy': 9,\n",
       " 'The Colonists': 349,\n",
       " 'The Downfall of Pompeii': 421,\n",
       " 'The Duke': 340,\n",
       " 'The Gallerist': 70,\n",
       " 'The Great Zimbabwe': 361,\n",
       " 'The Grizzled': 272,\n",
       " 'The Lord of the Rings: The Card Game': 92,\n",
       " 'The Manhattan Project': 178,\n",
       " 'The Manhattan Project: Energy Empire': 226,\n",
       " 'The Palaces of Carrara': 499,\n",
       " 'The Pillars of the Earth': 206,\n",
       " 'The Princes of Florence': 100,\n",
       " 'The Republic of Rome': 307,\n",
       " 'The Resistance': 141,\n",
       " 'The Resistance: Avalon': 69,\n",
       " 'The Voyages of Marco Polo': 38,\n",
       " 'Thebes': 350,\n",
       " 'Through the Ages: A New Story of Civilization': 1,\n",
       " 'Through the Ages: A Story of Civilization': 17,\n",
       " 'Through the Desert': 422,\n",
       " 'Thunder Alley': 491,\n",
       " 'Thunderstone': 480,\n",
       " 'Thunderstone Advance: Towers of Ruin': 264,\n",
       " 'Thunderstone: Dragonspire': 471,\n",
       " 'Thurn and Taxis': 325,\n",
       " 'Tichu': 103,\n",
       " 'Ticket to Ride': 109,\n",
       " 'Ticket to Ride: Europe': 83,\n",
       " 'Ticket to Ride: Mrklin': 204,\n",
       " 'Ticket to Ride: Nordic Countries': 102,\n",
       " 'Tigris & Euphrates': 60,\n",
       " 'Tikal': 194,\n",
       " \"Time's Up!\": 352,\n",
       " \"Time's Up! Title Recall!\": 262,\n",
       " \"Tinners' Trail\": 410,\n",
       " 'Tiny Epic Galaxies': 222,\n",
       " 'Tobago': 370,\n",
       " 'Tokaido': 414,\n",
       " 'Torres': 384,\n",
       " 'Tragedy Looper': 459,\n",
       " 'Trains': 331,\n",
       " 'Trajan': 59,\n",
       " 'Tribune: Primus Inter Pares': 430,\n",
       " 'Trickerion: Legends of Illusion': 186,\n",
       " 'Triumph & Tragedy': 426,\n",
       " 'Troyes': 61,\n",
       " 'Twilight Imperium (Third Edition)': 40,\n",
       " 'Twilight Struggle': 2,\n",
       " 'Tyrants of the Underdark': 334,\n",
       " \"Tzolk'in: The Mayan Calendar\": 32,\n",
       " 'Union Pacific': 428,\n",
       " 'Up Front': 327,\n",
       " 'Vasco da Gama': 401,\n",
       " 'Vegas Showdown': 374,\n",
       " 'Vikings': 284,\n",
       " 'Village': 101,\n",
       " 'Vinhos': 259,\n",
       " 'Vinhos Deluxe Edition': 300,\n",
       " 'Virgin Queen': 415,\n",
       " 'Viticulture': 96,\n",
       " 'Viticulture Essential Edition': 27,\n",
       " 'Wallenstein (first edition)': 295,\n",
       " 'War of the Ring (Second Edition)': 12,\n",
       " 'War of the Ring (first edition)': 68,\n",
       " 'Warhammer Quest: The Adventure Card Game': 310,\n",
       " 'Warhammer: Invasion': 407,\n",
       " \"Washington's War\": 380,\n",
       " 'Web of Power': 461,\n",
       " 'Wits & Wagers': 477,\n",
       " 'World Without End': 424,\n",
       " 'XCOM: The Board Game': 435,\n",
       " 'Xia: Legends of a Drift System': 151,\n",
       " 'YINSH': 119,\n",
       " 'Yedo': 406,\n",
       " 'Yokohama': 152,\n",
       " 'Yspahan': 405,\n",
       " 'ZhanGuo': 377,\n",
       " 'Zombicide': 278,\n",
       " 'Zombicide Season 2: Prison Outbreak': 367,\n",
       " 'Zombicide: Black Plague': 98,\n",
       " 'ZRTZ': 444}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games['Spyfall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "me=pd.DataFrame(data=['7 Wonders','Pandemic','Codenames','Dixit', 'Pandemic Legacy: Season 1','One Night Ultimate Werewolf','The Resistance','Coup',\n",
    "'Galaxy Trucker','Space Alert','Cosmic Encounter','Spyfall'], columns=['Games'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_collection = games2vec(me['Games'],games)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
